import os
import asyncio
import random
import json
import logging
from datetime import datetime, timedelta, timezone
from telethon import TelegramClient
from telethon.tl.functions.channels import GetFullChannelRequest
from telethon.tl.types import Channel
from telethon.errors import FloodWaitError, ChatAdminRequiredError, ChannelPrivateError
import pandas as pd
from dotenv import load_dotenv
import re
import sys
from proxy_pool import ProxyPool
from proxies import PROXIES
import glob
import subprocess
from notion_integration import NotionIntegration
from evaluate_chat import evaluate_chat

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('telegram_analyzer.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv(dotenv_path='.env')

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
results = []
# –°—á—ë—Ç—á–∏–∫ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–æ–≤ –∑–∞ —Å–µ—Å—Å–∏—é
analyzed_chats_total = 0
MAX_CHATS_BEFORE_PAUSE = 250
PAUSE_SECONDS = 600  # 10 –º–∏–Ω—É—Ç

class Cache:
    def __init__(self, cache_file='chat_cache.json'):
        self.cache_file = cache_file
        self.cache = self._load_cache()

    def _load_cache(self):
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫—ç—à–∞: {e}")
            return {}

    def _save_cache(self):
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫—ç—à–∞: {e}")

    def get(self, chat_id):
        return self.cache.get(chat_id)

    def set(self, chat_id, data):
        self.cache[chat_id] = data
        self._save_cache()

class TelegramAnalyzer:
    def __init__(self):
        self.proxy_pool = ProxyPool(PROXIES)
        self.accounts = []
        i = 1
        while True:
            api_id = os.getenv(f'API_ID_{i}')
            api_hash = os.getenv(f'API_HASH_{i}')
            if api_id and api_hash:
                self.accounts.append({
                    "api_id": api_id,
                    "api_hash": api_hash,
                    "session": f'telegram_analyzer_{i}'
                })
                i += 1
            else:
                break
        self.clients = []
        self.current_client_index = 0
        self.cache = Cache()
        self.rate_limit = 30  # –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É
        self.last_request_time = {}
        self.floodwait_until = [0] * len(self.accounts)  # timestamp –¥–æ –∫–æ—Ç–æ—Ä–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç "–∑–∞–º–æ—Ä–æ–∂–µ–Ω"
        self.notion = NotionIntegration()

    async def start(self):
        await self._init_clients()
        logger.info(f"–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! –í—Å–µ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {len(self.accounts)}")
        print("–ë–æ—Ç —Å–ª—É—à–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã...")

    async def _init_clients(self):
        for idx, account in enumerate(self.accounts):
            proxy = self.proxy_pool.get_proxy()
            session_path = os.path.abspath(f'telegram_analyzer_{idx+1}.session')
            client = TelegramClient(
                session_path,
                account["api_id"],
                account["api_hash"],
                proxy=proxy
            )
            try:
                await client.start()
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ {account['session']}: {e}")
                if 'database is locked' in str(e):
                    logger.error(f"Session-—Ñ–∞–π–ª {session_path} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–µ—Ç –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ Python.")
                raise
            self.clients.append(client)
            logger.info(f"–ö–ª–∏–µ–Ω—Ç {account['session']} (api_id={account['api_id']}) —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    async def get_next_client(self):
        import time
        now = time.time()
        for _ in range(len(self.clients)):
            idx = self.current_client_index
            if self.floodwait_until[idx] <= now:
                client = self.clients[idx]
                account = self.accounts[idx]
                logger.info(f"–°–ª–µ–¥—É—é—â–∏–π –∞–∫–∫–∞—É–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {account['session']} (api_id={account['api_id']})")
                self.current_client_index = (self.current_client_index + 1) % len(self.clients)
                return client, idx
            self.current_client_index = (self.current_client_index + 1) % len(self.clients)
        # –ï—Å–ª–∏ –≤—Å–µ –∞–∫–∫–∞—É–Ω—Ç—ã –≤ FloodWait ‚Äî –∂–¥—ë–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
        min_wait = min(self.floodwait_until) - now
        logger.warning(f"–í—Å–µ –∞–∫–∫–∞—É–Ω—Ç—ã –≤ FloodWait. –ñ–¥—É {int(min_wait)} —Å–µ–∫—É–Ω–¥...")
        if min_wait > 0:
            await asyncio.sleep(min_wait)
        # –ü–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
        return await self.get_next_client()

    async def restart_with_new_ip(self):
        """–ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –Ω–æ–≤—ã–º–∏ IP"""
        for i, client in enumerate(self.clients):
            await client.disconnect()
            await asyncio.sleep(5)  # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –¥–ª—è —Å–º–µ–Ω—ã IP
            proxy = self.proxy_pool.get_proxy()
            # –í–∞–∂–Ω–æ: –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç–∞ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ disconnect
            self.clients[i] = TelegramClient(
                self.accounts[i]["session"],
                self.accounts[i]["api_id"],
                self.accounts[i]["api_hash"],
                proxy=proxy
            )
            await self.clients[i].start()
            logger.info(f"–ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ: –ø–æ–ª—É—á–µ–Ω –Ω–æ–≤—ã–π IP —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ {self.accounts[i]['session']}!")

    async def get_chat_info(self, chat_id):
        import time
        try:
            cached_data = self.cache.get(chat_id)
            if cached_data and 'data' in cached_data:
                logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {chat_id}")
                return cached_data['data']
            else:
                logger.info(f"–ö—ç—à –¥–ª—è {chat_id} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç 'data', –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫—ç—à.")
            await asyncio.sleep(10)
            client, idx = await self.get_next_client()
            chat = await client.get_entity(chat_id)
            if isinstance(chat, Channel):
                await asyncio.sleep(5)
                full_chat = await client(GetFullChannelRequest(chat))
                result = {
                    'title': chat.title,
                    'description': full_chat.full_chat.about,
                    'members_count': getattr(full_chat.full_chat, 'participants_count', None),
                    'is_public': not chat.megagroup,
                    'date_created': chat.date.isoformat(),
                    'last_activity': datetime.now(timezone.utc).isoformat(),
                    'account_used': self.accounts[idx]["session"]
                }
                self.cache.set(chat_id, result)
                return result
        except FloodWaitError as e:
            wait_time = e.seconds
            logger.warning(f"‚ö†Ô∏è FloodWait: –∞–∫–∫–∞—É–Ω—Ç {self.accounts[self.current_client_index-1]['session']} –∑–∞–º–æ—Ä–æ–∂–µ–Ω –Ω–∞ {wait_time} —Å–µ–∫—É–Ω–¥ (—á–∞—Ç {chat_id})")
            self.floodwait_until[self.current_client_index-1] = time.time() + wait_time
            return await self.get_chat_info(chat_id)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —á–∞—Ç–µ {chat_id}: {e}")
            return None

    async def analyze_dau(self, chat_id, hours=24):
        import time
        try:
            client, idx = await self.get_next_client()
            messages = []
            async for message in client.iter_messages(chat_id, limit=100):
                if message.date > datetime.now(timezone.utc) - timedelta(hours=hours):
                    messages.append(message)
                else:
                    break
            unique_senders = set()
            for msg in messages:
                if hasattr(msg.from_id, 'user_id'):
                    unique_senders.add(msg.from_id.user_id)
            return {
                'total_messages': len(messages),
                'unique_senders': len(unique_senders),
                'time_period': f'–ü–æ—Å–ª–µ–¥–Ω–∏–µ {hours} —á–∞—Å–æ–≤',
                'account_used': self.accounts[idx]["session"]
            }
        except FloodWaitError as e:
            wait_time = e.seconds
            logger.warning(f"‚ö†Ô∏è FloodWait: –∞–∫–∫–∞—É–Ω—Ç {self.accounts[self.current_client_index-1]['session']} –∑–∞–º–æ—Ä–æ–∂–µ–Ω –Ω–∞ {wait_time} —Å–µ–∫—É–Ω–¥")
            self.floodwait_until[self.current_client_index-1] = time.time() + wait_time
            return await self.analyze_dau(chat_id, hours)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ DAU: {e}")
            return None

    async def analyze_dau_monthly(self, chat_id, days=30):
        import time
        try:
            client, idx = await self.get_next_client()
            from collections import defaultdict
            messages_by_day = defaultdict(set)
            days_with_messages = set()
            async for message in client.iter_messages(chat_id, limit=3000):
                if message.date > datetime.now(timezone.utc) - timedelta(days=days):
                    day = message.date.date()
                    days_with_messages.add(day)
                    if hasattr(message.from_id, 'user_id'):
                        messages_by_day[day].add(message.from_id.user_id)
                else:
                    break
            if not messages_by_day:
                return {'avg_dau': None, 'avg_dau_percent': None, 'days_with_messages': 0}
            daily_counts = [len(users) for users in messages_by_day.values()]
            avg_dau = round(sum(daily_counts) / len(daily_counts), 2)
            return {
                'avg_dau': avg_dau,
                'days_counted': len(daily_counts),
                'days_with_messages': len(days_with_messages),
                'account_used': self.accounts[idx]["session"]
            }
        except FloodWaitError as e:
            wait_time = e.seconds
            logger.warning(f"‚ö†Ô∏è FloodWait: –∞–∫–∫–∞—É–Ω—Ç {self.accounts[self.current_client_index-1]['session']} –∑–∞–º–æ—Ä–æ–∂–µ–Ω –Ω–∞ {wait_time} —Å–µ–∫—É–Ω–¥")
            self.floodwait_until[self.current_client_index-1] = time.time() + wait_time
            return await self.analyze_dau_monthly(chat_id, days)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ DAU –∑–∞ –º–µ—Å—è—Ü: {e}")
            return {'avg_dau': None, 'avg_dau_percent': None, 'days_with_messages': 0}

    async def generate_report(self, chat_id):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        chat_info = await self.get_chat_info(chat_id)
        if not chat_info:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Ç–µ"
        
        dau_info = await self.analyze_dau(chat_id)
        if not dau_info:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
        
        members_count = chat_info.get('members_count') or 0
        if members_count:
            dau_percent = round((dau_info['unique_senders'] / members_count * 100), 2)
        else:
            dau_percent = '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'
        
        report = f"""
üìä –û—Ç—á–µ—Ç –ø–æ —á–∞—Ç—É: {chat_info['title']}

üìù –û–ø–∏—Å–∞–Ω–∏–µ: {chat_info['description']}
üë• –ü–æ–¥–ø–∏—Å—á–∏–∫–æ–≤: {chat_info['members_count']}
üåê –¢–∏–ø: {'–ü—É–±–ª–∏—á–Ω—ã–π' if chat_info['is_public'] else '–ü—Ä–∏–≤–∞—Ç–Ω—ã–π'}
üìÖ –°–æ–∑–¥–∞–Ω: {chat_info['date_created']}

üìà –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞:
   ‚Ä¢ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {dau_info['total_messages']}
   ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π: {dau_info['unique_senders']}
   ‚Ä¢ DAU: {dau_percent}%
"""
        return report

def extract_username(chat_id):
    chat_id = chat_id.strip()
    if chat_id.startswith('@https://t.me/'):
        return chat_id[len('@https://t.me/'):]
    if chat_id.startswith('https://t.me/'):
        return chat_id[len('https://t.me/'):]
    if chat_id.startswith('@'):
        return chat_id[1:]
    return chat_id

def save_partial_report(results):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    if not results:
        logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return
        
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f'telegram_analysis_partial_{timestamp}.xlsx'
    
    try:
        df = pd.DataFrame(results)
        df.to_excel(filename, index=False)
        logger.info(f'–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}')
    except Exception as e:
        logger.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}')

def save_report(results):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ Excel"""
    if not results:
        print('–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.')
        return
    df = pd.DataFrame(results)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f'report_{timestamp}.xlsx'
    df.to_excel(filename, index=False)
    print(f'–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª–µ {filename}')

def save_last_24h_results(results):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞"""
    if not results:
        logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return
        
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f'last_24h_analysis_{timestamp}.xlsx'
    
    try:
        df = pd.DataFrame(results)
        df.to_excel(filename, index=False)
        logger.info(f'–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}')
        print(f'\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}')
    except Exception as e:
        logger.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}')

def get_resume(members, avg_dau, avg_dau_percent, days_with_messages, days_in_month=30):
    if members is None or pd.isna(members):
        return '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'
    try:
        members = float(members)
    except:
        return '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'
    if members >= 1000:
        if (avg_dau is not None and avg_dau < 5 and avg_dau_percent is not None and avg_dau_percent < 0.1) or (days_with_messages is not None and days_with_messages < days_in_month * 0.3):
            return '–ú–µ—Ä—Ç–≤—ã–π —á–∞—Ç'
        elif avg_dau_percent is not None and avg_dau_percent > 10:
            return '–§–ª—É–¥–∏–ª–∫–∞'
        else:
            return '–ñ–∏–≤–æ–π —á–∞—Ç'
    elif members >= 100:
        if (avg_dau is not None and avg_dau < 1 and avg_dau_percent is not None and avg_dau_percent < 0.1) or (days_with_messages is not None and days_with_messages < days_in_month * 0.3):
            return '–ú–µ—Ä—Ç–≤—ã–π —á–∞—Ç'
        elif avg_dau_percent is not None and avg_dau_percent > 15:
            return '–§–ª—É–¥–∏–ª–∫–∞'
        elif avg_dau is not None and avg_dau >= 1:
            return '–ñ–∏–≤–æ–π —á–∞—Ç (–Ω–∏—à–µ–≤–æ–π/–æ–±—ä—è–≤–ª–µ–Ω–∏–π)'
        else:
            return '–ñ–∏–≤–æ–π —á–∞—Ç'
    else:
        if avg_dau is not None and avg_dau < 1 or (days_with_messages is not None and days_with_messages < days_in_month * 0.3):
            return '–ú–µ—Ä—Ç–≤—ã–π —á–∞—Ç'
        elif avg_dau_percent is not None and avg_dau_percent > 20:
            return '–§–ª—É–¥–∏–ª–∫–∞'
        else:
            return '–ñ–∏–≤–æ–π —á–∞—Ç'

async def main():
    analyzer = TelegramAnalyzer()
    await analyzer.start()
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∞—Ç—ã —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º 'To Analyze' —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
        try:
            chats_to_analyze = analyzer.notion.get_chats_to_analyze_with_pagination()
            logger.info(f"[DEBUG] –í—Å–µ–≥–æ —á–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (To Analyze, —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π): {len(chats_to_analyze)}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —á–∞—Ç–æ–≤ –∏–∑ Notion: {e}")
            chats_to_analyze = []
        
        print(f"–ì–æ—Ç–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É —á–∞—Ç–æ–≤, –≤—Å–µ–≥–æ –≤ –æ—á–µ—Ä–µ–¥–∏: {len(chats_to_analyze)}")
        logger.info(f"–ì–æ—Ç–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É —á–∞—Ç–æ–≤, –≤—Å–µ–≥–æ –≤ –æ—á–µ—Ä–µ–¥–∏: {len(chats_to_analyze)}")
        
        for chat_page in chats_to_analyze:
            chat_properties = chat_page.get("properties", {})
            chat_id_property = chat_properties.get("–ö–∞–Ω–∞–ª/—á–∞—Ç", {})
            rich_text = chat_id_property.get("rich_text", [])
            chat_id = rich_text[0].get("text", {}).get("content", "") if rich_text else ""
            if not chat_id:
                logger.warning("[DEBUG] –ü—Ä–æ–ø—É—â–µ–Ω —á–∞—Ç –±–µ–∑ chat_id")
                    continue
            logger.info(f"[DEBUG] –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ —á–∞—Ç–∞ {chat_id}")
            print(f"[DEBUG] –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —á–∞—Ç: {chat_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Ç–µ
            chat_info = await analyzer.get_chat_info(chat_id)
                        if not chat_info:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Ç–∞ {chat_id}, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Å—Ç–∞—Ç—É—Å Error –≤ Notion")
                error_results = {"chat_id": chat_id, "name": ""}
                logger.warning(f"–ü–µ—Ä–µ–¥–∞—é –≤ update_chat_analysis: {error_results}")
                analyzer.notion.update_chat_analysis(chat_page["id"], error_results, status="Error")
                continue
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º DAU
            dau_info = await analyzer.analyze_dau(chat_id)
            monthly_dau = await analyzer.analyze_dau_monthly(chat_id)
            if not dau_info or not monthly_dau:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ DAU –¥–ª—è —á–∞—Ç–∞ {chat_id}, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Å—Ç–∞—Ç—É—Å Error –≤ Notion")
                error_results = {"chat_id": chat_id, "name": chat_info.get('title', '') if chat_info else ""}
                logger.warning(f"–ü–µ—Ä–µ–¥–∞—é –≤ update_chat_analysis: {error_results}")
                analyzer.notion.update_chat_analysis(chat_page["id"], error_results, status="Error")
                            continue
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª–µ–π
            members_count = chat_info.get("members_count", 0)
            dau = dau_info.get("unique_senders", 0) if dau_info else 0
            dau_percent = round((dau / members_count * 100), 2) if members_count and dau is not None else 0
            monthly_avg_dau = monthly_dau.get("avg_dau", 0) if monthly_dau else 0
            monthly_avg_dau_percent = round((monthly_avg_dau / members_count * 100), 2) if members_count and monthly_avg_dau is not None else 0
            days_with_messages = monthly_dau.get("days_with_messages", 0) if monthly_dau else 0
            total_messages = dau_info.get("total_messages", 0) if dau_info else 0
            resume = get_resume(members_count, monthly_avg_dau, monthly_avg_dau_percent, days_with_messages)
            cache_date = datetime.now().isoformat()
            account_used = chat_info.get("account_used", "")
            description = chat_info.get("description", "")
            name = chat_info.get("title", "")

            analysis_results = {
                "chat_id": chat_id,
                "name": name,
                "description": description,
                "members_count": members_count,
                "dau": dau,
                "dau_percent": dau_percent,
                "monthly_avg_dau": monthly_avg_dau,
                "monthly_avg_dau_percent": monthly_avg_dau_percent,
                "days_with_messages": days_with_messages,
                "total_messages": total_messages,
                "resume": resume,
                "cache_date": cache_date,
                "account": account_used,
                "activity_score": monthly_avg_dau_percent,
                "notes": f"DAU –∑–∞ 24 —á–∞—Å–∞: {dau}\n"
                        f"DAU –∑–∞ –º–µ—Å—è—Ü: {monthly_avg_dau}\n"
                        f"–ü—Ä–æ—Ü–µ–Ω—Ç DAU: {monthly_avg_dau_percent}%"
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ Notion
            analyzer.notion.update_chat_analysis(chat_page["id"], analysis_results)
            logger.info(f"[DEBUG] –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {chat_id} –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ Notion")
            
            # ML-–æ—Ü–µ–Ω–∫–∞
            try:
                print(f"–í—ã–ø–æ–ª–Ω—è—é ML-–æ—Ü–µ–Ω–∫—É –¥–ª—è {chat_id}")
                evaluate_chat(chat_id)
                print(f"ML-–æ—Ü–µ–Ω–∫–∞ –¥–ª—è {chat_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                logger.info(f"ML-–æ—Ü–µ–Ω–∫–∞ –¥–ª—è {chat_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                except Exception as e:
                print(f"–û—à–∏–±–∫–∞ ML-–æ—Ü–µ–Ω–∫–∏ –¥–ª—è {chat_id}: {e}")
                logger.error(f"–û—à–∏–±–∫–∞ ML-–æ—Ü–µ–Ω–∫–∏ –¥–ª—è {chat_id}: {e}")
            
            # –î–µ–ª–∞–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∞–º–∏
            await asyncio.sleep(random.uniform(5, 10))
    
    except Exception as e:
        logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
    finally:
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Excel
        analyzer.notion.export_to_excel(f"notion_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ –∫–ª–∏–µ–Ω—Ç—ã
        for client in analyzer.clients:
            await client.disconnect()

if __name__ == "__main__":
        asyncio.run(main())
    